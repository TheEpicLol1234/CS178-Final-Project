{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a7c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b33be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetic_data.csv\")\n",
    "ids_mapping = pd.read_csv(\"IDS_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0839a0a",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1e9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"?\" with NaN for simplicity\n",
    "df = df.replace(\"?\", np.nan)\n",
    "\n",
    "# Create binary target: 1 = readmitted <30 days, 0 = otherwise\n",
    "if \"readmitted\" in df.columns:\n",
    "    df[\"target\"] = df[\"readmitted\"].apply(lambda x: 1 if x == \"<30\" else 0)\n",
    "    df = df.drop([\"readmitted\"], axis=1)\n",
    "\n",
    "# Drop ID and unhelpful columns\n",
    "drop_cols = [\n",
    "    \"encounter_id\",               # Unique identifier\n",
    "    \"patient_nbr\",                # Unique per person\n",
    "    \"weight\",                     # ~97% missing\n",
    "    \"payer_code\",                 # ~40% missing\n",
    "    \"medical_specialty\",          # High cardinality\n",
    "    \"examide\",                    # Almost all 0s\n",
    "    \"citoglipton\",                # Almost all 0s\n",
    "    \"metformin-rosiglitazone\",    # Deprecated, rare\n",
    "    \"metformin-pioglitazone\"      # Deprecated, rare\n",
    "]\n",
    "\n",
    "# Add any overlapping columns from ids_mapping (if applicable)\n",
    "drop_cols += [col for col in ids_mapping.columns if col in df.columns]\n",
    "\n",
    "# Drop specified columns safely\n",
    "df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Drop columns with excessive missing values (>50%) or high cardinality objects\n",
    "df = df.loc[:, df.isnull().mean() < 0.5]\n",
    "df = df.drop(columns=[\n",
    "    col for col in df.select_dtypes(include=\"object\") \n",
    "    if df[col].nunique() > 50\n",
    "])\n",
    "\n",
    "# Drop remaining rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df_dummies = pd.get_dummies(df, drop_first=True, dtype=float)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_dummies.drop(\"target\", axis=1)\n",
    "y = df_dummies[\"target\"]\n",
    "\n",
    "# Convert to sparse matrix\n",
    "X_sparse = sparse.csr_matrix(X.values)\n",
    "\n",
    "# Train/test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(\n",
    "    X_sparse, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features without centering (sparse-compatible)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# Prepare metrics dictionary\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fdb90-2abb-4e05-9a4a-2f271c473082",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    decided to use tsne because it allows us to turn this multi dimensional space into a 2d space\n",
    "    therefore, we can see what model is the best to use, as a guess  \n",
    "    then we can compare THIS inital guess to the FINAL guess\n",
    "'''\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "X_embedded = tsne.fit_transform(X_train_scaled.toarray())\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "# 0 (NOT readmitted) = blue || 1 (readmitted) = red\n",
    "scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_train, cmap=\"coolwarm\", alpha=0.6)\n",
    "plt.title()\n",
    "plt.xlabel(\"x vals\")\n",
    "plt.ylabel(\"y vals\")\n",
    "plt.colorbar(scatter, label=\"Readmitted (<30 days = 1)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbd5a5",
   "metadata": {},
   "source": [
    "k-Nearest Neighors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c96814",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Convert sparse matrices to dense arrays\n",
    "X_train_dense = X_train_scaled.toarray()\n",
    "X_test_dense = X_test_scaled.toarray()\n",
    "\n",
    "knn.fit(X_train_dense, y_train)\n",
    "y_pred_knn = knn.predict(X_test_dense)\n",
    "\n",
    "metrics[\"kNN\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_knn),\n",
    "    \"Precision\": precision_score(y_test, y_pred_knn),\n",
    "    \"Recall\": recall_score(y_test, y_pred_knn),\n",
    "    \"F1\": f1_score(y_test, y_pred_knn),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_knn)\n",
    "}\n",
    "\n",
    "for metric_name, value in metrics[\"kNN\"].items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838133f4",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "metrics[\"Logistic Regression\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_lr),\n",
    "    \"Precision\": precision_score(y_test, y_pred_lr),\n",
    "    \"Recall\": recall_score(y_test, y_pred_lr),\n",
    "    \"F1\": f1_score(y_test, y_pred_lr),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_knn)\n",
    "}\n",
    "\n",
    "for metric_name, value in metrics[\"Logistic Regression\"].items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350c09c",
   "metadata": {},
   "source": [
    "Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "\n",
    "metrics[\"Feedforward NN\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_mlp),\n",
    "    \"Precision\": precision_score(y_test, y_pred_mlp),\n",
    "    \"Recall\": recall_score(y_test, y_pred_mlp),\n",
    "    \"F1\": f1_score(y_test, y_pred_mlp),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_knn)\n",
    "}\n",
    "for metric_name, value in metrics[\"Feedforward NN\"].items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95557f4c",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f20ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt.predict(X_test_scaled)\n",
    "\n",
    "metrics[\"Decision Tree\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_dt),\n",
    "    \"Precision\": precision_score(y_test, y_pred_dt),\n",
    "    \"Recall\": recall_score(y_test, y_pred_dt),\n",
    "    \"F1\": f1_score(y_test, y_pred_dt),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_knn)\n",
    "}\n",
    "for metric_name, value in metrics[\"Decision Tree\"].items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfcf00",
   "metadata": {},
   "source": [
    "Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ebe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(title, y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(\"kNN Confusion Matrix\", y_test, y_pred_knn)\n",
    "plot_confusion(\"Logistic Regression Confusion Matrix\", y_test, y_pred_lr)\n",
    "plot_confusion(\"Feedforward NN Confusion Matrix\", y_test, y_pred_mlp)\n",
    "plot_confusion(\"Decision Tree Confusion Matrix\", y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46055d1a",
   "metadata": {},
   "source": [
    "Visualization of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict):\n",
    "    metrics_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"]\n",
    "    classifiers = list(metrics_dict.keys())\n",
    "    values = {metric: [metrics_dict[classifier][metric] for classifier in classifiers] for metric in metrics_names}\n",
    "\n",
    "    x = np.arange(len(classifiers))\n",
    "    width = 0.2\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i, metric in enumerate(metrics_names):\n",
    "        plt.bar(x + i*width, values[metric], width=width, label=metric)\n",
    "\n",
    "    plt.xticks(x + width*1.5, classifiers)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Metrics by Classifier\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs178_env)",
   "language": "python",
   "name": "cs178_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a7c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b33be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetic_data.csv\")\n",
    "ids_mapping = pd.read_csv(\"IDS_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0839a0a",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1e9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether or not hospital patient will be readmitted within 30 days\n",
    "\n",
    "# Replace \"?\" with NaN to standardize missing values\n",
    "df = df.replace(\"?\", np.nan)\n",
    "\n",
    "# Target variable includes those recently readmitted (within 30 days)\n",
    "# creates a binary target where 1 = readmitted <30, 0 otherise\n",
    "if \"readmitted\" in df.columns:\n",
    "    df[\"target\"] = df[\"readmitted\"].apply(lambda x: 1 if x == \"<30\" else 0)\n",
    "    df = df.drop([\"readmitted\"], axis=1)\n",
    "    \n",
    "# Drop ID and unhelpful columns\n",
    "drop_cols = [\"encounter_id\", \"patient_nbr\", \"weight\", \"payer_code\", \"medical_specialty\", \"examide\",  \"citoglipton\", \"metformin-rosiglitazone\", \"metformin-pioglitazone\"]\n",
    "df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Drop columns with excessive missing values or high cardinality\n",
    "df = df.loc[:, df.isnull().mean() < 0.5]\n",
    "df = df.drop(columns=[col for col in df.select_dtypes(include=\"object\") if df[col].nunique() > 50])\n",
    "df = df.dropna()\n",
    "\n",
    "# One-hot encode with float dtype to avoid object dtype issues\n",
    "df_dummies = pd.get_dummies(df, drop_first=True, dtype=float)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_dummies.drop(\"target\", axis=1)\n",
    "y = df_dummies[\"target\"]\n",
    "\n",
    "# Convert to scipy sparse matrix\n",
    "X_sparse = sparse.csr_matrix(X.values)\n",
    "\n",
    "# Train/test split (sparse matrix version)\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(\n",
    "    X_sparse, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# Feature scaling using sparse-compatible scaler (no centering)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# Prepare to store metrics for later model evaluation\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fdb90-2abb-4e05-9a4a-2f271c473082",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    decided to use t-sne because it allows us to turn this multi dimensional space into a 2d space\n",
    "    therefore, we can see what model is the best to use, as a guess  \n",
    "    then we can compare THIS inital guess to the FINAL result\n",
    "'''\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "X_embedded = tsne.fit_transform(X_train_scaled.toarray())\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "# 0 (NOT readmitted) = blue || 1 (readmitted) = red\n",
    "scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_train, cmap=\"coolwarm\", alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Readmitted (<30 days = 1)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbd5a5",
   "metadata": {},
   "source": [
    "k-Nearest Neighors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c96814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8791\n",
      "Precision: 0.2480\n",
      "Recall: 0.0379\n",
      "F1: 0.0658\n",
      "AUC: 0.5117\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrices to dense arrays (KNN doesn't support sparse input)\n",
    "X_train_dense = X_train_scaled.toarray()\n",
    "X_test_dense = X_test_scaled.toarray()\n",
    "\n",
    "metrics[\"kNN\"] = {}\n",
    "\n",
    "for k in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_dense, y_train)\n",
    "    \n",
    "    y_pred_knn = knn.predict(X_test_dense)\n",
    "    \n",
    "    metrics[\"kNN\"][k] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_knn),\n",
    "        \"Precision\": precision_score(y_test, y_pred_knn, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred_knn),\n",
    "        \"F1\": f1_score(y_test, y_pred_knn),\n",
    "        \"AUC\": roc_auc_score(y_test, y_pred_knn)\n",
    "    }\n",
    "\n",
    "    print(f\"\\nk = {k}\")\n",
    "    for metric_name, value in metrics[\"kNN\"][k].items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "# Extract metric values for each k\n",
    "ks = list(metrics[\"kNN\"].keys())\n",
    "accuracy = [metrics[\"kNN\"][k][\"Accuracy\"] for k in ks]\n",
    "precision = [metrics[\"kNN\"][k][\"Precision\"] for k in ks]\n",
    "recall = [metrics[\"kNN\"][k][\"Recall\"] for k in ks]\n",
    "f1 = [metrics[\"kNN\"][k][\"F1\"] for k in ks]\n",
    "auc = [metrics[\"kNN\"][k][\"AUC\"] for k in ks]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(ks, accuracy, label=\"Accuracy\", marker='o')\n",
    "plt.plot(ks, precision, label=\"Precision\", marker='o')\n",
    "plt.plot(ks, recall, label=\"Recall\", marker='o')\n",
    "plt.plot(ks, f1, label=\"F1 Score\", marker='o')\n",
    "plt.plot(ks, auc, label=\"AUC\", marker='o')\n",
    "\n",
    "plt.xlabel(\"Number of Neighbors (k)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"KNN Classifier Metrics vs k\")\n",
    "plt.xticks(ks)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838133f4",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c032c1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6669\n",
      "Precision: 0.1717\n",
      "Recall: 0.5142\n",
      "F1: 0.2574\n",
      "AUC: 0.6002\n"
     ]
    }
   ],
   "source": [
    "# Define a list of candidate values for C (inverse of regularization strength)\n",
    "candidate_C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_score = 0\n",
    "best_C = None\n",
    "\n",
    "for C in candidate_C_values:\n",
    "    # Initialize logistic regression with current C and other fixed hyperparameters\n",
    "    model = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        solver='lbfgs',\n",
    "        C=C\n",
    "    )\n",
    "    \n",
    "    # Perform k-fold cross-validation on training data\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Calculate mean validation score\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    # Update best parameters if current mean score is better\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_C = C\n",
    "\n",
    "# Train final model using best_C on full training data\n",
    "final_model = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    class_weight='balanced', \n",
    "    max_iter=1000, \n",
    "    random_state=42, \n",
    "    solver='lbfgs', \n",
    "    C=best_C\n",
    ")\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "metrics[\"Logistic Regression\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_lr),\n",
    "    \"Precision\": precision_score(y_test, y_pred_lr),\n",
    "    \"Recall\": recall_score(y_test, y_pred_lr),\n",
    "    \"F1\": f1_score(y_test, y_pred_lr),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_lr)\n",
    "}\n",
    "\n",
    "for metric_name, value in metrics[\"Logistic Regression\"].items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350c09c",
   "metadata": {},
   "source": [
    "Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "\n",
    "metrics[\"Feedforward NN\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_mlp),\n",
    "    \"Precision\": precision_score(y_test, y_pred_mlp),\n",
    "    \"Recall\": recall_score(y_test, y_pred_mlp),\n",
    "    \"F1\": f1_score(y_test, y_pred_mlp),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_mlp)\n",
    "}\n",
    "for metric_name, value in metrics[\"Feedforward NN\"].items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95557f4c",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f20ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max_depth = 31\n",
      "Accuracy: 0.8002\n",
      "Precision: 0.1514\n",
      "Recall: 0.1692\n",
      "F1: 0.1598\n",
      "AUC: 0.5246\n",
      "\n",
      "max_depth = 32\n",
      "Accuracy: 0.8001\n",
      "Precision: 0.1592\n",
      "Recall: 0.1823\n",
      "F1: 0.1700\n",
      "AUC: 0.5303\n",
      "\n",
      "max_depth = 33\n",
      "Accuracy: 0.7974\n",
      "Precision: 0.1538\n",
      "Recall: 0.1788\n",
      "F1: 0.1653\n",
      "AUC: 0.5272\n"
     ]
    }
   ],
   "source": [
    "metrics[\"Decision Tree\"] = {}\n",
    "\n",
    "for depth in range(31,60):\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train_scaled, y_train)\n",
    "    y_pred_dt = dt.predict(X_test_scaled)\n",
    "    \n",
    "    metrics[\"Decision Tree\"][depth] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_dt),\n",
    "        \"Precision\": precision_score(y_test, y_pred_dt, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred_dt),\n",
    "        \"F1\": f1_score(y_test, y_pred_dt),\n",
    "        \"AUC\": roc_auc_score(y_test, y_pred_dt)\n",
    "    }\n",
    "    print(f\"\\nmax_depth = {depth}\")\n",
    "    for metric_name, value in metrics[\"Decision Tree\"][depth].items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfcf00",
   "metadata": {},
   "source": [
    "Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ebe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(title, y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(\"kNN Confusion Matrix\", y_test, y_pred_knn)\n",
    "plot_confusion(\"Logistic Regression Confusion Matrix\", y_test, y_pred_lr)\n",
    "plot_confusion(\"Feedforward NN Confusion Matrix\", y_test, y_pred_mlp)\n",
    "plot_confusion(\"Decision Tree Confusion Matrix\", y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46055d1a",
   "metadata": {},
   "source": [
    "Visualization of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict):\n",
    "    metrics_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"]\n",
    "    classifiers = list(metrics_dict.keys())\n",
    "    values = {metric: [metrics_dict[classifier][metric] for classifier in classifiers] for metric in metrics_names}\n",
    "\n",
    "    x = np.arange(len(classifiers))\n",
    "    width = 0.2\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i, metric in enumerate(metrics_names):\n",
    "        plt.bar(x + i*width, values[metric], width=width, label=metric)\n",
    "\n",
    "    plt.xticks(x + width*1.5, classifiers)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Metrics by Classifier\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs178_env)",
   "language": "python",
   "name": "cs178_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
